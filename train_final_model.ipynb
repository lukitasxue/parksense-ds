{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ParkSense - Production Training Pipeline ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from xgboost import XGBRegressor\n",
                "import os"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Loading\n",
                "Loads historical sensor data exported from Supabase."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_data(file_path='data/supabase_snapshots.csv'):\n",
                "    \"\"\"\n",
                "    Loads raw snapshot data and converts timestamps.\n",
                "    \"\"\"\n",
                "    print(\"Loading snapshot data...\")\n",
                "    df = pd.read_csv(file_path)\n",
                "    df['status_timestamp'] = pd.to_datetime(df['status_timestamp'])\n",
                "    return df"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Neighborhood Grouping\n",
                "Groups bays into blocks of 20 to reduce noise from individual sensors."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "def neighborhood_grouping(df):\n",
                "    \"\"\"\n",
                "    Groups individual bays into 'neighborhoods' of 20 units.\n",
                "    \"\"\"\n",
                "    print(\"Grouping bays into neighborhoods...\")\n",
                "    df['group_id'] = (df['kerbsideid'] // 20) * 20\n",
                "    df['is_occupied'] = df['status'].apply(lambda x: 1 if x == 'Present' else 0)\n",
                "    return df"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Time-Series Resampling\n",
                "Converts raw events into standardized 15-minute intervals."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "def timeseries_resampling(df):\n",
                "    \"\"\"\n",
                "    Resamples data into 15-minute heartbeats calculating occupancy ratios.\n",
                "    \"\"\"\n",
                "    print(\"Preprocessing time-series into 15-min intervals...\")\n",
                "    group_ts = df.groupby(['group_id', pd.Grouper(key='status_timestamp', freq='15min')])['is_occupied'].mean().reset_index()\n",
                "    group_ts.columns = ['group_id', 'timestamp', 'occupancy_ratio']\n",
                "    group_ts = group_ts.sort_values(['group_id', 'timestamp'])\n",
                "    return group_ts"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Feature Engineering\n",
                "Creates the inputs (X) and target (y) for the model, including time features and lags."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "def feature_engineering(group_ts):\n",
                "    \"\"\"\n",
                "    Engineering features (lags and time-based) and defines the target variable.\n",
                "    \"\"\"\n",
                "    print(\"Engineering features (lags and time-based)...\")\n",
                "    group_ts = group_ts.copy()\n",
                "    group_ts['hour'] = group_ts['timestamp'].dt.hour\n",
                "    group_ts['day_of_week'] = group_ts['timestamp'].dt.dayofweek\n",
                "    \n",
                "    # Lag Features: Looking at what happened 15m and 30m ago\n",
                "    group_ts['lag_15m'] = group_ts.groupby('group_id')['occupancy_ratio'].shift(1)\n",
                "    group_ts['lag_30m'] = group_ts.groupby('group_id')['occupancy_ratio'].shift(2)\n",
                "    \n",
                "    # Target Variable: 15 minutes into the future\n",
                "    group_ts['target_15m'] = group_ts.groupby('group_id')['occupancy_ratio'].shift(-1)\n",
                "    \n",
                "    model_data = group_ts.dropna()\n",
                "    \n",
                "    features = ['group_id', 'occupancy_ratio', 'hour', 'day_of_week', 'lag_15m', 'lag_30m']\n",
                "    X = model_data[features]\n",
                "    y = model_data['target_15m']\n",
                "    \n",
                "    return X, y, features"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Model Training\n",
                "Trains the XGBoost Regressor on the processed dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_model(X, y):\n",
                "    \"\"\"\n",
                "    Trains the XGBoost model with production-ready hyperparameters.\n",
                "    \"\"\"\n",
                "    print(f\"Training XGBoost model on {len(X)} samples...\")\n",
                "    model = XGBRegressor(\n",
                "        n_estimators=300,\n",
                "        learning_rate=0.05,\n",
                "        max_depth=7,\n",
                "        subsample=0.8,\n",
                "        colsample_bytree=0.8\n",
                "    )\n",
                "    model.fit(X, y)\n",
                "    return model"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Model Export\n",
                "Saves the model and feature metadata for use by the FastAPI backend."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "def export_model(model, features, output_dir='models'):\n",
                "    \"\"\"\n",
                "    Exports the trained model and feature list for the backend.\n",
                "    \"\"\"\n",
                "    os.makedirs(output_dir, exist_ok=True)\n",
                "    model_path = os.path.join(output_dir, 'parking_model_15m.ubj')\n",
                "    features_path = os.path.join(output_dir, 'features.txt')\n",
                "    \n",
                "    model.save_model(model_path)\n",
                "    with open(features_path, 'w') as f:\n",
                "        f.write(\",\".join(features))\n",
                "        \n",
                "    print(f\"Success! Model saved to {model_path}\")\n",
                "    print(f\"Features expected by BE: {features}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Final Execution Function\n",
                "This orchestrates the entire pipeline by calling the functions defined above."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading snapshot data...\n",
                        "Grouping bays into neighborhoods...\n",
                        "Preprocessing time-series into 15-min intervals...\n",
                        "Engineering features (lags and time-based)...\n",
                        "Training XGBoost model on 287065 samples...\n",
                        "Success! Model saved to models\\parking_model_15m.ubj\n",
                        "Features expected by BE: ['group_id', 'occupancy_ratio', 'hour', 'day_of_week', 'lag_15m', 'lag_30m']\n"
                    ]
                }
            ],
            "source": [
                "def train_production_model():\n",
                "    \"\"\"\n",
                "    Complete end-to-end pipeline: load -> process -> engineer -> train -> export.\n",
                "    \"\"\"\n",
                "    # 1. Load\n",
                "    df = load_data()\n",
                "    \n",
                "    # 2. Process\n",
                "    df = neighborhood_grouping(df)\n",
                "    group_ts = timeseries_resampling(df)\n",
                "    \n",
                "    # 3. Engineer\n",
                "    X, y, features = feature_engineering(group_ts)\n",
                "    \n",
                "    # 4. Train\n",
                "    model = train_model(X, y)\n",
                "    \n",
                "    # 5. Export\n",
                "    export_model(model, features)\n",
                "\n",
                "# Run the full pipeline\n",
                "if __name__ == \"__main__\":\n",
                "    train_production_model()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
